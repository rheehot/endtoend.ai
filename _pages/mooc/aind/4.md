---
layout: page
title: "AIND: 4. Informed Search"
permalink: /mooc/aind/4/
---

### Informed Search

Uninformed Search is great if we have no additional information. However, in many cases, we can acquire additional information and optimize our search. This search strategy of ranking successors is **Informed Search**. The best additional information for Informed Search is th estimate of the distance between the state and the goal state.

### Greedy Best-First Search

Uninformed Search has no idea where the goal could be, so it needs to search uniformly in all actions. This can be especially slow if there is a lot of possible actions.

![Contour of Uniform Cost Search](/assets/mooc/aind/4/uniform_cost_contour.png)

**Greedy Best-First Search** is a naive search algorithm uses the distance to the goal state. The search is directed towards the goal.

![Contour of Greedy Best-First Search](/assets/mooc/aind/4/greedy_best_first_search_contour.png)

Sometimes, this search will find the best path quickly. However, if there are obstacles, Greedy Best-First Search could fail to find the optimal path. If the shortest path involves temporarily moving further away from the goal, the search will fail to find that path.

![Contour of Greedy Best-First Search with Obstacle](/assets/mooc/aind/4/greedy_best_first_search_obstacle_contour.png)

### A* Search

To solve the problem of Greedy Best-First Search, we use **A* Search** algorithm in practice. In A* search, we expand the path that has a minimum value of $f = g + h$, where $g, h$ are

$g(\text{path}) = \text{path cost}$

$h(\text{path}) = \text{estimated distance to goal}$

![A* Search Diagram](/assets/mooc/aind/4/a_star_search.png)

$g(\text{path})$ keeps the path short, while $h(\text{path})$ keeps us focused on the goal. A* search is an optimal search strategy: it finds the shortest path while expanding minimum number of paths.

![Arad to Bucharest Map with A* search](/assets/mooc/aind/4/arad_to_bucharest_a_star.png)

Let's try A* search in the Arad-to-Bucharest example. The number in red denotes the estimated distance from that state to the goal state (Bucharest).

![Arad to Bucharest Map with A* search Part 1](/assets/mooc/aind/4/arad_to_bucharest_a_star_2.png)

In Arad, the A* search will choose to explore Sibiu, since it has the $f$ cost of 393, better than Zerind's 449 and Timisoara's 447.

![Arad to Bucharest Map with A* search Part 2](/assets/mooc/aind/4/arad_to_bucharest_a_star_3.png)

Note that similar to Uninformed Search algorithms, in A* search we also cannot immediately terminate when we reach the goal state. We need to wait until the goal state has the lower cost in all the frontier.

### Heuristic function $h$

The heuristic function of the A* search is important. To guarantee that the A* search finds the optimal path, $h$ should never overestimate distance to goal. We also say that $h$ must be **optimistic** or **admissible**.

![Importance of Optimistic Heuristic function](/assets/mooc/aind/4/optimistic_heuristic_function.png)

Let's say that we found a path $p$ that has the least $f$ cost in all the frontier. 

Since $p$ reached the goal, $h=0$, so $f(p)$ is the actual cost of the path $p$. 

$$ \text{Real Cost of }p = f(p) $$

Because $h$ is optimistic, we know that for any path $p'$ in the frontier,

$$ f(p') = g(p') + h(p') \leq \text{Real Cost of }p' $$

We assumed that we found $p$ such that $f(p) \leq f(p')$, so

$$ \text{Real Cost of }p = f(p) \leq f(p') \leq \text{Real Cost of }p'$$

Assuming that all step costs have nonnegative value, any path to goal state must have a cost of at least the real cost of $p'$, so we can guarantee that $p$ is the shortest path.

(Note that the argument is slightly different for graph search)

### Vacuum World

We looked at a state space with a physical state where a graph seemed natural. However, we can also use search techniques with different state space.

 ![Vacuum World](/assets/mooc/aind/4/vacuum_world.png)

In **Vacuum World**, there are two locations A and B, and either locations can have dirt in it. This problem has a state space of size 8.

![Diagram of actions in Vacuum World](/assets/mooc/aind/4/vacuum_world_graph.png)

There are three actions possible: move left (L), move right (R), and sweep (S). The diagram above illustrates the state transitions by actions.

### Sliding Blocks Puzzle (15 Puzzle)

![Sliding Blocks Puzzle](/assets/mooc/aind/4/sliding_blocks.png)

Here is another problem that can be solved with a search technique. The puzzle has 16 cells in a 4-by-4 grid. 15 cells are occupied by sliding blocks labeled 1 to 15. A block can slide to the empty cell if it is neighboring the empty cell. The goal state is the state above.

![One Heuristic for Sliding Blocks](/assets/mooc/aind/4/sliding_blocks_h1.png)

What would be a good heuristic function $h$? One possible heuristic $h_1$ is the number of misplaced blocks. In the state above, $h_1 = 4$. This is optimistic since every block on the wrong cell needs to move at least once.

![Another Heuristic for Sliding Blocks](/assets/mooc/aind/4/sliding_blocks_h2.png)

Another possible heuristic $h_2$ is the sum of distance the block has to move to its write position. In the state above, $h_2=4$. This is also optimistic since the block cannot move faster then one space per move, so it takes at least $h_2$ moves to reach the goal state.

Note that $h_1 \leq h_2$ in all cases. Then, in a A* search, $h_2$ will expand fewer paths compared to $h_1$.

### Generating a Relaxed Problem

Using the correct Heuristic function is necessary to find the optimal path, and better heuristic function can result in faster search. Therefore, we could say that the "intelligence" in search lies in finding the heuristic function. Is there a way to automatically generate a heuristic?

It is possible to create heuristics by loosening the restriction of the problem. The restriction of the problem was:

```
A block can move A -> B if
 1. A and B are adjacent, and
 2. B is blank
```

Suppose we remove the second restriction. This is called **relaxing** the problem. Then, this is the heuristic $h_2$. If we remove both restrictions, then this is the heuristic $h_1$. The heuristics generated this way are guaranteed to be optimistic since it took that much cost with relaxed restrictions. 

Then, $h^* = \max(h_1, h_2, \ldots)$ is guaranteed to be optimistic as well. Since $h^*$ is bigger than any heuristic $h_i$, this searches less paths than any heuristic $h_i$. The only downside is that calculating heuristics $h_i$ would take more time.

### Implementation Tips

To represent a path in a compute, it is common to use **nodes**. A node should have a state at the end of the path, the action it took to get there, the total cost, and the **pointer to its parent**.

To choose a data structure to store the frontier, we need to think of its operations. We need to remove best item, insert new items, and query for membership. A **priority queue** would make insert and removal fast, and a **set** would make query fast. The most efficient implementations of search use both the priority queue and a set for the frontier.

The explored list is easier to represent since we only need to insert new items and check for membership. This can be represented by a single set.
