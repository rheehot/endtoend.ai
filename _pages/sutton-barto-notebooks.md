---
layout: page
title: Sutton and Barto Notebooks | End to End AI
permalink: /sutton-barto-notebooks
header_description: Sutton and Barto Notebooks
---

(In Progress)

[Sutton and Barto의 Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html) is a seminal textbook of Reinforcement Learning due to its thorough explanations accompanied with abundant examples. The book contains numerous insightful figures. These are implementations of the figures.

## 목차

1. Introduction
2. Multi-armed Bandits
   * [Figure 2.2: Epsilon Greedy Policy](https://github.com/seungjaeryanlee/sutton-barto-notebooks/blob/master/en/chapter02/figure_2_2/e_greedy.ipynb)
   * [Figure 2.3: Optimistic Initialization](https://github.com/seungjaeryanlee/sutton-barto-notebooks/blob/master/en/chapter02/figure_2_3/optimistic.ipynb)
   * [Figure 2.4: Upper Confidence Bound](https://github.com/seungjaeryanlee/sutton-barto-notebooks/blob/master/en/chapter02/figure_2_4/ucb.ipynb)
   * [Figure 2.5: Preference Agent](https://github.com/seungjaeryanlee/sutton-barto-notebooks/blob/master/en/chapter02/figure_2_5/gradient.ipynb)
   * [Figure 2.6: Parameter Study](https://github.com/seungjaeryanlee/sutton-barto-notebooks/blob/master/en/chapter02/figure_2_6/parameters.ipynb)
3. Finite Markov Decision Processes
4. Dynamic Programming
   * [Figure 4.1: Policy Evaluation](https://github.com/seungjaeryanlee/sutton-barto-notebooks/blob/master/en/chapter04/figure_4_1/policy_evaluation.ipynb)
5. Monte Carlo Methods
6. Temporal-Difference Learning
   * [Example 6.6: SARSA vs. Q-Learning](https://github.com/seungjaeryanlee/sutton-barto-notebooks/blob/master/en/chapter06/example_6_6/cliff_walking.ipynb)
   * [Figure 6.5: Q-Learning vs. Double Q-Learning](https://github.com/seungjaeryanlee/sutton-barto-notebooks/blob/master/en/chapter06/figure_6_5/double_q_learning.ipynb)
7. $n$-step Bootstrapping
8. Planning and Learning with Tabular Methods
9. On-policy Prediction with Approximation
10. On-policy Control with Approximation
11. Off-policy Methods with Approximation
12. Eligibility Traces
13. Policy Gradient Methods
    * [Example 13.1: Short Corridor Gridworld](https://github.com/seungjaeryanlee/sutton-barto-notebooks/blob/master/en/chapter13/example_13_1/short_corridor.ipynb)
