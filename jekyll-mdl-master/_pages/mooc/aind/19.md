---
layout: page
title: "AIND: 19. Approximate Inference"
permalink: /mooc/aind/19
---

In the [last two lessons](/mooc/aind/17), we learned about *exact* inference algorithms that computed the exact probabilities. In this lesson, we will learn about *approximate* inference algorithms through sampling.

### Sampling

![Sampling model]({{ "assets/mooc/aind/19/sampling.png" | absolute_url }})

(The table for $P(C)$ should not include the second column)

Suppose we have a model shown by the network above. Suppose we want to find the probability that the grass is wet. We can use enumeration or variable elimination for exact inference, but we can also simulate the environment and sample the possible outcomes to approximate the probabilities.

We look at variables that has all its parents defined. It is the variable $C$  (for Cloudy). We sample from the probability table, and suppose we got $+c$. Then, $S$ and $R$ have all their parents defined, so we sample their values from their probability distribution. We only consider the case where $C = +c$. Suppose we get $-s$ and $+r$. Finally, we sample $W$ where $S = -s$ and $R = +r$. Suppose we get $W = +w$. With this, we generated a complete sample: $(+c, -s, +r ,+w)$. We continuously generate these samples and count the number of times $W = +w$.

With the infinite number of samples, the approximated probability will equal the actual probability. We say that the sampling method is **consistent**.

### Rejection Sampling

In the example above, we approximated $P(W)$. Let's consider a conditional probability $P(+w \mid -c)$. We need to look at samples with $C = -c$ and count the number of times $W = +w$. In that case, we cannot use all samples. For example, the sample $(+c, -s, +r, +w)$ we generated above cannot be used since $C = +c$. In other words, we **reject** the samples that don't match the conditional probability. The rejection sampling is also consistent: with infinite number of samples, the approximate probability will be the actual probability.

![Problem with Rejection Sampling]({{ "assets/mooc/aind/19/rejection_sampling.png" | absolute_url }})

However, the problem with rejection sampling is that if the probability is rare. Suppose we have a simple network where Alarm ringing is dependent on Burglary. If we want to approximate $P(B \mid +a)$, we need to find samples of form $(-b, +a)$ or $(+b, +a)$. However, both alarm malfunction and burglary is rare, so most samples we generate will have $A = -a$.

### Likelihood Weighting

To fix the problem of rejecting many samples, we use a new method called the **Likelihood Weighting**. In this method, we fix the values of the evidence variables. However, fixing the values makes the samples inconsistent. To make the method consistent, we need to save the weigh the samples by the likelihood of fixed evidence variables.

![Likelihood Weighting]({{ "assets/mooc/aind/19/likelihood_weighting.png" | absolute_url }})

Suppose we want to calculate $P(R \mid +s, +w)$. Like before, we sample $C$. Suppose we sample $C = +c$. Then, we fix the $S = +s$. Since $P(+s \mid +c) = 0.1$, we multiply $0.1$ to the weight. We sample $R$, and suppose we sample $R = +r$. Finally, we fixed $W = +w$, so we multiply $P(+w \mid +s, +r) = 0.99$ to the weight.  thus, we sampled $(+c, +s, +r, +w)$ with weight $0.099$.

However, likelihood sampling also has a problem. Suppose we want to estimate $P(C \mid +s, +r)$. Then, we first sample $C$, then we fix $S, R$ and multiply the weight. Then, we sample $W$. The sampling of $C$ is not affected by values of $S$ and $R$, so it is generated at random from $P(C)$. Thus, most of the time, it will generate samples that is unlikely based on the evidence (i.e. have low weight).

### Gibbs Sampling

A solution to this problem is the **Gibbs sampling**: a sampling method that takes into account all evidence variables into account instead of just upstream evidence variables.

This is done by a process called **Monte Carlo Markov Chain** (MCMC). Given a set of variables, we not only fix the evidence variables, but also assign values to all non-evidence variables. Then, at each iteration, we select one non-evidence variables and re-select its value based on other variables to create a new sample. Although we omit the proof, this method is consistent.

![Example of Gibbs sampling]({{ "assets/mooc/aind/19/gibbs_sampling.png" | absolute_url }})

