---
layout: post
title: "AIND: 14. Probability"
permalink: /mooc/aind/14
---

Agents may need to handle uncertainty due to various reasons partial observability or stochastic environment. We have seen agents that use belief states to combat uncertainty, but we need to consider every possible situation no matter how unlikely, which leads to huge belief states.

Instead, we use probability to concisely express the degree of uncertainty. Bayes network is used in almost all "smart" computers, including machine learning, finance, robotics, etc. It is the building block of many advanced AI techniques. For the next few lessons, we will learn about the basics of Bayesian probability.

### Basic Probability

**Probability** is used to express and manage uncertainty. Let's review some basic ideas of probability.

* $P(A)$ denotes the probability of event $A$ happening.

* $P(\lnot A)$ denotes the probability of event $A$ not happening. If $P(A) = p$, then $P(\lnot A) = 1 - p$. This is called the **complementary probability**.

* $P(A, B)$ is denotes the probability that both $A$ and $B$ occurred, and is called the **joint probability** of $A$ and $B$.

* $P(A \mid B)$ denotes the probability that $A$ occurs given that $B$ occurred.

  * $P(A \mid B) = \frac{P(A, B)}{P(B)}$

  * $P(\lnot A \mid B) = 1 - P(A \mid B)$
  * $ P(A) = \sum_b P(A \mid B = b) P(B = b)$
    * This is called the **total probability**.

The probability $P(A)$ is called the **prior**, referring to the degree of belief in the absence of any other information. The probability $P(A \mid B)$ is called the **posterior**, referring to the degree of belief given some evidence $B$.

### Cancer Example

Suppose that we have a patient that has undergone a test for cancer. We denote the person event of having cancer as $C$, and we denote the test results $T$ with $+, -$ referring to positive and negative results. We are given the following probabilities:

* $P(C) = 0.0001$
* $P(+ \mid C) = 0.99$ (known as **sensitivity** or **true positive rate**)
* $P(- \mid \lnot C) = 0.99$ (known as **specificity** or **true negative rate**)

We want to know $P(C \mid +)$, the probability that a person has cancer given that the test came out positive. This can be calculated by looking at all patients that had positive test results, and checking how many of them had cancer. In other words,

$$ P (C \mid +) = \frac{P(C, +)}{P(C, +) + P(\lnot C, +)}$$

$P(A, B) = P(A \mid B) P(B)​$, so we can calculate the joint probabilities:

* $P(C, +) = P(+ \mid C) P(C) = 0.000099$
* $P(\lnot C, +) = P(+ \mid \lnot C) P(\lnot C) = 0.009999$

Thus,

$$ P(C \mid +) = \frac{0.000099}{0.000099 + 0.009999} \simeq 0.01 = 1\%$$

Surprisingly, the patient with a positive test result has only $1\%$ chance of cancer!

![Explanation of Cancer Example]({{ "assets/AIND-14/cancer_tree.png" | absolute_url }})

It might be easier to understand this phenomenon by assuming that there are 1 million people. The tree above shows how the people would be divided based on their sickness and their test results. If a patient got a positive test result, he or she must be one of the 99 people or one of the 9999 people. The patient is has probability of $\frac{99} {99 + 9999} < 1\%$ to be one of the 99 people with cancer, and $\frac{9999}{99+9999} > 99%$ probability to be one of the 9999 people without cancer. In other words, the test's error rate of $1\%$ is much higher than the cancer rate of $0.01 \%$, so you are more likely to be part of the wrongly classified patient.

### Absolute and Conditional Independence

Events can be unrelated to each other. For example, if you have two coins and flip each coin once, then the probability of heads in each coin is unrelated. We say that that two events are **independent** or **absolutely independent** if the occurrence of one does not affect the occurrence of the other. We denote that two events $A$ and $B$ are independent by writing $A \perp B$. If $A \perp B$, then the following statements hold:

- $P(A \mid B) = P(A)$
- $P(B \mid A) = P(B)$
- $P(A, B) = P(A)P(B)$

Two events $A, B$ are **conditionally independent** given another event $C$ if the occurrence of $A$ and the occurrence of $B$ are independent given $C$. We denote this by writing $A \perp B \mid C$.

Note that neither absolute independence and conditional independence implies the other. First, conditional independence does not imply absolute independence. A person's height and the person's vocabulary size is not independent: if you plot a graph, you will see a general trend of tall people having high vocabulary size. However, if you add age, then the two are conditionally independent.

The bewildering part is that absolute independence does not imply conditional independence.  This can be explained using an idea called *explaining away*.

### Explaining Away

Consider the following problem: your happiness $H$ is affected by the weather being sunny $S$ or getting a raise $R$. Assume that weather and getting a raise is independent. ($S \perp R$).

![Confounding Cause]({{ "assets/AIND-14/confounding_cause.png" | absolute_url }})

Now, suppose I know that you are happy. I have certain degree of belief that you are happy due to getting a raise. Then, I see that the weather is sunny today. The weather being sunny can *explain away* your cause of happiness, so I believe less that you got a raise. In contrast, if the weather was rainy, then I believe it is more likely that you got a raise.

Let's treat this formally. First, let's compute $P(R \mid H)$.

$$ P(R \mid H) \propto P(H \mid R)P(R) = P(H \mid R, S)P(S) + P(H \mid R, \lnot S)P(\lnot S) = 0.0097 $$

$$ P(\lnot R \mid H) \propto P(H \mid \lnot R)P(\lnot R) = P(H \mid \lnot R, S)P(S) + P(H \mid \lnot R, \lnot S)P(\lnot S) = 0.5148 ​$$

Thus,

$P(R \mid H) = \frac{0.0097}{0.0097 + 0.5148} \simeq 0.0185$

Now, let's compute $P(R \mid H, S)$.

$$ P(R \mid H,S) = \frac{P(H \mid R, S)P(R \mid S)}{P(H \mid S)} = \frac{P(H \mid R, S)P(R)}{P(H \mid R,S)P(R) + P(H \mid \lnot R, S) P(\lnot R)} \simeq 0.0142$$

Finally, let's compute $P(R \mid H, \lnot S)$.

$$  P(R \mid H, \lnot S) = \frac{P(H \mid R, \lnot S)P(R \mid \lnot S)}{P(H \mid \lnot S)} = \frac{P(H \mid R, \lnot S)P(R)}{P(H \mid R, \lnot S)P(R) + P(H \mid \lnot R, \lnot S) P(\lnot R)} \simeq 0.0833$$
