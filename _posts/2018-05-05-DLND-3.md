---
layout: post
title: "DLND: 3. Gradient Descent"
permalink: /mooc/dlnd/3
---

In the [last lesson](/mooc/dlnd/2), we learned about error function that quantifies the error of the boundary. In this lesson, we will learn about **gradient descent**, a stepwise method to reduce error. With that, we will complete the **logistic regression** algorithm the fundamental algorithm in Deep Learning.

### Gradient Descent

**Gradient descent** is the way to reduce the error by taking a step of steepest descent. The direction of the steepest descent is the **gradient** of the error function, which is a vector form of the partial derivative of the error function. 

$$\nabla E = (\frac{\delta E}{\delta w_1}, \ldots, \frac{\delta E}{\delta w_n}, \frac{\delta E}{\delta b})$$

In reality, the gradient is just a derivative generalized to functions.

![Example of a derivative]({{ "assets/DLND-3/derivative_example.png" | absolute_url }})

The gradient contains the partial derivatives $\frac{\delta E}{\delta w_i}$ and $\frac{\delta E}{\delta b}$ for each weight. These partial derivatives tell the model the direction to change the weights $w_i$ and the bias $b$.

![Gradient Descent Hiker]({{ "assets/DLND-3/gradient_descent.png" | absolute_url }})

Then, using the partial derivatives, we can update every weight and bias the following way:

$$ w_i' := w_i - \alpha \frac{\delta E}{\delta w_i} $$

$$ b' := b - \alpha \frac{\delta E}{\delta b} $$

where $\alpha$ is the learning rate. By performing gradient descent continuously, we can reach the minima. Here is a visualization of the gradient descent with a contour plot.

![Gradient Descent in Contour Plot]({{ "assets/DLND-3/gradient_descent_contour.png" | absolute_url }})

### Computing Gradients

To calculate $\frac{\delta E}{\delta w_i}$, we compute individual partial derivatives and use **chain rule**.

$\frac{\delta \hat{y}}{\delta w_i} = \frac{\delta \hat{y}}{\delta z} \frac{\delta z}{\delta w_i}â€‹$

Remember that $E = -y \ln(\hat{y}) - (1 - y) \ln (1 - \hat{y})$. (The notation might be different, but the idea and the meaning is identical.)  Therefore,

$$ \frac{\delta E}{\delta \hat{y}} = -\frac{y}{\hat{y}} - \frac{1-y}{1-\hat{y}}$$.

$\frac{\delta \hat{y}}{\delta z}$ is the derivative of the sigmoid function. and the derivative of the sigmoid function is $\frac{\delta \sigma(x)}{\delta x} = \sigma(x)(1 - \sigma(x))$. Therefore,

$$ \frac{\delta \hat{y}}{\delta z} = \hat{y}(1 - \hat{y})$$

Finally, since $z = Wx + b$,

$$\frac{\delta z}{\delta w_i} = \frac{\delta (w_1x_1 + \ldots + w_nx_n + b)}{\delta w_i} = x_i$$

Therefore,

$$ \frac{\delta E}{\delta w_i} = (-\frac{y}{\hat{y}} - \frac{1-y}{1-\hat{y}})\hat{y}(1 - \hat{y}) x_i = -(y - \hat{y})x_i$$

Similarly, we can calculate $\frac{\delta E}{\delta b}$.

$$ \frac{\delta E}{\delta b} = \frac{\delta E}{\delta \hat{y}} \frac{\delta \hat{y}}{\delta z} \frac{\delta z}{\delta b} = -(y - \hat{y})$$

Therefore, the gradient of error function $\nabla E$ can be written simply as

$$\nabla E = -(y - \hat{y}) (x_1, \ldots, x_n, 1)$$

### Caveats

The gradient descent seems to have one problem: it cannot discern between global and local minima. Depending on the start location, we could reach the local minima and never find the global minima.

![Example of a Local Minima]({{ "assets/DLND-3/local_minima.png" | absolute_url }})

In this case, we use an algorithm called RMSprop that accounts for momentum or use multiple initial points.

### Logistic Regression

We have now learned enough to complete the **Logistic Regression** algorithm. This algorithm is the fundamental algorithm in Machine Learning.

1. We build a random model by randomly initializing the weights $W$ and biases $b$.
2. Repeat $n$ **epochs**:
   1. Calculate the error from given data with the *cross entropy error function*.
   2. Update weights and bias with *gradient descent*

This algorithm is nearly identical to the perceptron algorithm that we learned in the [Lesson 1](/mooc/dlnd/1). The key difference is that in the perceptron algorithm, the prediction is discrete ($\hat{y} \in \{0, 1\}$), but in this algorithm, the prediction is continuous ($\hat{y} \in [0, 1]$). Therefore, the perceptron algorithm does not update the model for correctly classified data, but the logistic regression algorithm still updates the model to increase the probability of the correctly classified data.

![Diagram of a continuous perceptron]({{ "assets/DLND-3/continuous_perceptron_diagram.png" | absolute_url }})

