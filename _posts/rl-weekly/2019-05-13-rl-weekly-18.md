---
layout: post
title: "RL Weekly 18: Survey of Domain Randomization Techniques for Sim-to-Real Transfer, and Evaluating Deep RL with ToyBox"
author: Seungjae Ryan Lee
permalink: /rl-weekly/18
tags:
 - reinforcement-learning
 - rl-weekly

image: /assets/blog/rl-weekly/18/domain_randomization.png
image_type: contain
excerpt: "This week, we introduce a survey of Domain Randomization Techniques for Sim-to-Real Transfer and ToyBox, a suite of redesigned Atari Environments for experimental evaluation of deep RL."

nav:
- name: "Domain Randomization"
  permalink: "#domain-randomization-for-sim2real-transfer"
- name: "Toybox"
  permalink: "#toybox"

related:
- title: "RL Weekly 17: Information Asymmetry in KL-regularized Objective, Real-world Challenges to RL, and Fast and Slow RL"
  link: /rl-weekly/17
  image: /assets/blog/rl-weekly/17/asymmetry.png
  image_type: contain
- title: "RL Weekly 19: Curious Object-Based Search Agent, AutoRL, and Multiplicative Compositional Policies"
  link: /rl-weekly/19
  image: /assets/blog/rl-weekly/19/cobra.png
  image_type: contain
---



{% include revue.html %}





## Domain Randomization for Sim2Real Transfer

<div class="w80" style="margin: 10px auto;">
  <img src="{{ absolute_url }}/assets/blog/rl-weekly/18/domain_randomization.png" alt="">
</div>

**What it is**

Lilian Weng, a researcher at OpenAI, wrote a blog post summarizing various Domain Randomization methods for Sim-to-Real transfer. Sim-to-Real is a method of pretraining agents in simulated environments and fine-tuning them in the real world. Domain Randomization is a technique of creating a variety of simulation environments by randomizing various properties. By training a model that performs well on all these environments, we expect that the model will also perform well on real environment.

The blog post explains the reasoning behind domain randomization, and introduces Uniform Domain Randomization and Guided Domain Randomization. Uniform Domain Randomization uniformly samples various simulation parameters to randomize the environment. Guided Domain Randomization replaces the uniform sampling and "guides" parameters so that the randomized simulated environments are realistic.

**Why it matters**

In many real application of RL (especially robotics), it is impractical to train the agent in the real world, as the real world cannot be sped up. This is especially the case for robotics, since robots are expensive and can wear out from numerous operations. Thus, sim-to-real techniques are essential methods to increase real-world sample efficiency. Among various sim-to-real methods, domain randomization is particularly attractive as it requires little to no real data.

**Read more**

- [Domain Randomization for Sim2Real Transfer (Blog Post)](https://lilianweng.github.io/lil-log/2019/05/05/domain-randomization.html)

**External Resources**

- [sim2realAI](https://sim2realai.github.io/): This website indexes progress of sim-to-real transfer.






## ToyBox for Experimental Evaluation of Deep RL {#toybox}

<div class="w100" style="margin: 10px auto;">
  <img src="{{ absolute_url }}/assets/blog/rl-weekly/18/toybox.png" alt="">
</div>

**What it is & Why it matters**

The Arcade Learning Environment (ALE) has been the standard test suite for evaluating deep RL algorithms. Although ALE has accelerated the development of algorithms, it is not very customizable, making in difficult to qualitatively analyze the agent's abilities. Researchers at University of Massachusetts Amherst created ToyBox, a faster, highly customizable, drop-in replacement for Atari Breakout, Amidar, and Space Invaders.

**Read more**

- [Toybox: A Suite of Environments for Experimental Evaluation of Deep Reinforcement Learning (ArXiv Preprint)](https://arxiv.org/abs/1905.02825)

**External Resources**

- [Arcade Learning Environment (GitHub Repo)](https://github.com/mgbellemare/Arcade-Learning-Environment)
- [OpenAI Gym: Atari Environments](http://gym.openai.com/envs/#atari)
- [Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents](https://arxiv.org/abs/1709.06009)






---

Some more exciting news in RL:

- DeepMind published [**Meta-learning of Sequential Strategies**](https://arxiv.org/abs/1905.03030), reviewing the capabilities of memory-based meta-learning.
- Week 11 of UC Berkeley's Deep Unsupervised Learning course have been published, which reviews [**Representation Learning in Reinforcement Learning**](https://www.youtube.com/watch?v=Yvll3P1UW5k).
- [**MineRL Competition**](http://minerl.io/competition/) page was revealed. The competition starts on June 1st.
- **Task Agnostic Reinforcement Learning Workshop** was held in ICLR2019. The workshop videos are up at [SlidesLive](https://slideslive.com/38915490/r09-taskagnostic-reinforcement-learning)!
- Researchers at KAIST showed that [dimensional-wise importance sampling weight clipping](https://arxiv.org/abs/1905.02363) can improve the performance of PPO.
